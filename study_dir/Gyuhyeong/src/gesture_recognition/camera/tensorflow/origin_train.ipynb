{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 30, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = ['next', 'prev', 'idel']\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_next_1714367781.npy'),\n",
    "    np.load('dataset/seq_prev_1714367781.npy'),\n",
    "    np.load('dataset/seq_idel_1714367781.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 30, 99)\n",
      "(1080,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 데이터 타입 변경 및 레이블 원-핫 인코딩\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\gesture-recognition\\py3.9\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,253,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7680</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,043</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,253,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m262,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7680\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │        \u001b[38;5;34m23,043\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,129,923</span> (8.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,129,923\u001b[0m (8.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,129,923</span> (8.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,129,923\u001b[0m (8.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    LSTM(512, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "# EarlyStopping 콜백 추가\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# ReduceLROnPlateau 콜백 조정\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1, mode='min', min_lr=0.00001)\n",
    "\n",
    "# ModelCheckpoint 콜백 조정\n",
    "model_checkpoint = ModelCheckpoint('models/updated_model_2.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 콜백 정의\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint('models/updated_model.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto'),\n",
    "#     ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=50, verbose=1)\n",
    "# ]\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7839 - loss: 0.4734\n",
      "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to models/updated_model_2.keras\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.7919 - loss: 0.4572 - val_accuracy: 1.0000 - val_loss: 6.9278e-05 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9974 - loss: 0.0045\n",
      "Epoch 2: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9975 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 6.7968e-06 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.6601e-05\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.6500e-05 - val_accuracy: 1.0000 - val_loss: 4.3941e-06 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 9.6863e-06\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 9.6370e-06 - val_accuracy: 1.0000 - val_loss: 1.7782e-06 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.6714e-06\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.6519e-06 - val_accuracy: 1.0000 - val_loss: 1.1082e-06 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.0098e-06\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.9977e-06 - val_accuracy: 1.0000 - val_loss: 8.2232e-07 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.6014e-06\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.5800e-06 - val_accuracy: 1.0000 - val_loss: 6.2254e-07 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.5051e-06\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.5164e-06 - val_accuracy: 1.0000 - val_loss: 4.9891e-07 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.3754e-06\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.3728e-06 - val_accuracy: 1.0000 - val_loss: 4.0619e-07 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.2105e-06\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.2009e-06 - val_accuracy: 1.0000 - val_loss: 3.2120e-07 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 8.4456e-07\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 8.4241e-07 - val_accuracy: 1.0000 - val_loss: 2.6822e-07 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 8.0921e-07\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 8.0404e-07 - val_accuracy: 1.0000 - val_loss: 2.5718e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 6.6026e-07\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 6.6242e-07 - val_accuracy: 1.0000 - val_loss: 2.4725e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 6.1465e-07\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 6.1886e-07 - val_accuracy: 1.0000 - val_loss: 2.3621e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 7.4114e-07\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 7.3384e-07 - val_accuracy: 1.0000 - val_loss: 2.2628e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 5.3822e-07\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 5.3982e-07 - val_accuracy: 1.0000 - val_loss: 2.1634e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 5.8881e-07\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 5.8898e-07 - val_accuracy: 1.0000 - val_loss: 2.0862e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.8313e-07\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 4.8570e-07 - val_accuracy: 1.0000 - val_loss: 1.9979e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 5.0069e-07\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 4.9973e-07 - val_accuracy: 1.0000 - val_loss: 1.9206e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 4.9797e-07\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 4.9694e-07 - val_accuracy: 1.0000 - val_loss: 1.8213e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.9307e-07\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 4.9077e-07 - val_accuracy: 1.0000 - val_loss: 1.7550e-07 - learning_rate: 2.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.8946e-07\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.9292e-07 - val_accuracy: 1.0000 - val_loss: 1.7440e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 4.3806e-07\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.3868e-07 - val_accuracy: 1.0000 - val_loss: 1.7109e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.1818e-07\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.2019e-07 - val_accuracy: 1.0000 - val_loss: 1.7109e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.8304e-07\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.8040e-07 - val_accuracy: 1.0000 - val_loss: 1.7219e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.9595e-07\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.9635e-07 - val_accuracy: 1.0000 - val_loss: 1.7219e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.4559e-07\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 4.4458e-07 - val_accuracy: 1.0000 - val_loss: 1.7109e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.8460e-07\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.8611e-07 - val_accuracy: 1.0000 - val_loss: 1.6778e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.9485e-07\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.9537e-07 - val_accuracy: 1.0000 - val_loss: 1.6778e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.0772e-07\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.0793e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.0836e-07\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.0789e-07 - val_accuracy: 1.0000 - val_loss: 1.6226e-07 - learning_rate: 4.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.7531e-07\n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.7653e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 4.7019e-07\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.6515e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.9177e-07\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.9194e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.8471e-07\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.8507e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.3951e-07\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.4413e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 4.3740e-07\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 4.3475e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.9932e-07\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.9949e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.1535e-07\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.1549e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.4350e-07\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.4611e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.7727e-07\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.7873e-07 - val_accuracy: 1.0000 - val_loss: 1.6336e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.8446e-07\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.8499e-07 - val_accuracy: 1.0000 - val_loss: 1.6226e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.6741e-07\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.6796e-07 - val_accuracy: 1.0000 - val_loss: 1.6226e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.0772e-07\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 4.0605e-07 - val_accuracy: 1.0000 - val_loss: 1.6115e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.9099e-07\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.9015e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.9412e-07\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.9259e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 4.3671e-07\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.3404e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.0271e-07\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.0169e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.6633e-07\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.6656e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.5764e-07\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.5838e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.1295e-07\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 4.1079e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 3.4716e-07\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 3.4959e-07 - val_accuracy: 1.0000 - val_loss: 1.6005e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.0589e-07\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.0585e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.5371e-07\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.5378e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 4.1800e-07\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 4.1456e-07 - val_accuracy: 1.0000 - val_loss: 1.5784e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.3472e-07\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.3692e-07 - val_accuracy: 1.0000 - val_loss: 1.5784e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.6540e-07\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.6612e-07 - val_accuracy: 1.0000 - val_loss: 1.5784e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.3141e-07\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.3206e-07 - val_accuracy: 1.0000 - val_loss: 1.5784e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 3.7623e-07\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 3.7758e-07 - val_accuracy: 1.0000 - val_loss: 1.5784e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.4442e-07\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.4593e-07 - val_accuracy: 1.0000 - val_loss: 1.5784e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.6160e-07\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.6219e-07 - val_accuracy: 1.0000 - val_loss: 1.5674e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.3021e-07\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.3153e-07 - val_accuracy: 1.0000 - val_loss: 1.5563e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.3089e-07\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.3189e-07 - val_accuracy: 1.0000 - val_loss: 1.5453e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.6226e-07\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 3.6196e-07 - val_accuracy: 1.0000 - val_loss: 1.5453e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.4121e-07\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.4320e-07 - val_accuracy: 1.0000 - val_loss: 1.5453e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.8072e-07\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.7893e-07 - val_accuracy: 1.0000 - val_loss: 1.5453e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.9025e-07\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.8981e-07 - val_accuracy: 1.0000 - val_loss: 1.5453e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.8625e-07\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.8481e-07 - val_accuracy: 1.0000 - val_loss: 1.5343e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.8443e-07\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.8285e-07 - val_accuracy: 1.0000 - val_loss: 1.5122e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.8773e-07\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.8507e-07 - val_accuracy: 1.0000 - val_loss: 1.5122e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.3651e-07\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.3747e-07 - val_accuracy: 1.0000 - val_loss: 1.5122e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.9971e-07\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.9766e-07 - val_accuracy: 1.0000 - val_loss: 1.5122e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.6901e-07\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.6852e-07 - val_accuracy: 1.0000 - val_loss: 1.5122e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.7184e-07\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.7143e-07 - val_accuracy: 1.0000 - val_loss: 1.5122e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.2368e-07\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.2716e-07 - val_accuracy: 1.0000 - val_loss: 1.5122e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.6665e-07\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.6588e-07 - val_accuracy: 1.0000 - val_loss: 1.4791e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.0254e-07\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.0082e-07 - val_accuracy: 1.0000 - val_loss: 1.4680e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.7264e-07\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.7110e-07 - val_accuracy: 1.0000 - val_loss: 1.4460e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.6792e-07\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.6673e-07 - val_accuracy: 1.0000 - val_loss: 1.4349e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.5045e-07\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.5145e-07 - val_accuracy: 1.0000 - val_loss: 1.4349e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.3503e-07\n",
      "Epoch 81: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.3472e-07 - val_accuracy: 1.0000 - val_loss: 1.4239e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.7973e-07\n",
      "Epoch 82: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.7696e-07 - val_accuracy: 1.0000 - val_loss: 1.4128e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.8812e-07\n",
      "Epoch 83: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.8493e-07 - val_accuracy: 1.0000 - val_loss: 1.4018e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.2564e-07\n",
      "Epoch 84: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.2559e-07 - val_accuracy: 1.0000 - val_loss: 1.4018e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.9333e-07\n",
      "Epoch 85: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.9615e-07 - val_accuracy: 1.0000 - val_loss: 1.4018e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.8742e-07\n",
      "Epoch 86: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.8426e-07 - val_accuracy: 1.0000 - val_loss: 1.3908e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.4465e-07\n",
      "Epoch 87: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 4.3784e-07 - val_accuracy: 1.0000 - val_loss: 1.3908e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.0062e-07\n",
      "Epoch 88: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.0329e-07 - val_accuracy: 1.0000 - val_loss: 1.3908e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.1593e-07\n",
      "Epoch 89: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.1643e-07 - val_accuracy: 1.0000 - val_loss: 1.3797e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.4140e-07\n",
      "Epoch 90: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.4101e-07 - val_accuracy: 1.0000 - val_loss: 1.3687e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.8564e-07\n",
      "Epoch 91: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.8802e-07 - val_accuracy: 1.0000 - val_loss: 1.3687e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.0298e-07\n",
      "Epoch 92: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.0436e-07 - val_accuracy: 1.0000 - val_loss: 1.3687e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.1474e-07\n",
      "Epoch 93: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.1468e-07 - val_accuracy: 1.0000 - val_loss: 1.3577e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.8879e-07\n",
      "Epoch 94: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.9053e-07 - val_accuracy: 1.0000 - val_loss: 1.3577e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.0117e-07\n",
      "Epoch 95: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 3.0270e-07 - val_accuracy: 1.0000 - val_loss: 1.3577e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.7130e-07\n",
      "Epoch 96: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.7312e-07 - val_accuracy: 1.0000 - val_loss: 1.3577e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.0288e-07\n",
      "Epoch 97: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.0322e-07 - val_accuracy: 1.0000 - val_loss: 1.3577e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.2542e-07\n",
      "Epoch 98: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.2472e-07 - val_accuracy: 1.0000 - val_loss: 1.3577e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.8663e-07\n",
      "Epoch 99: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.8826e-07 - val_accuracy: 1.0000 - val_loss: 1.3466e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.8528e-07\n",
      "Epoch 100: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.8106e-07 - val_accuracy: 1.0000 - val_loss: 1.3245e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.5812e-07\n",
      "Epoch 101: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.6110e-07 - val_accuracy: 1.0000 - val_loss: 1.3135e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.7522e-07\n",
      "Epoch 102: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.7820e-07 - val_accuracy: 1.0000 - val_loss: 1.3135e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.8211e-07\n",
      "Epoch 103: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.8358e-07 - val_accuracy: 1.0000 - val_loss: 1.3025e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.0244e-07\n",
      "Epoch 104: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.0223e-07 - val_accuracy: 1.0000 - val_loss: 1.3025e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.8631e-07\n",
      "Epoch 105: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.8656e-07 - val_accuracy: 1.0000 - val_loss: 1.3025e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.3250e-07\n",
      "Epoch 106: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.3078e-07 - val_accuracy: 1.0000 - val_loss: 1.3025e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.2193e-07\n",
      "Epoch 107: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.2078e-07 - val_accuracy: 1.0000 - val_loss: 1.2914e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.1448e-07\n",
      "Epoch 108: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.1400e-07 - val_accuracy: 1.0000 - val_loss: 1.2914e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.1202e-07\n",
      "Epoch 109: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.1216e-07 - val_accuracy: 1.0000 - val_loss: 1.2914e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.2178e-07\n",
      "Epoch 110: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1982e-07 - val_accuracy: 1.0000 - val_loss: 1.2914e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.1975e-07\n",
      "Epoch 111: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.1802e-07 - val_accuracy: 1.0000 - val_loss: 1.2804e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.2268e-07\n",
      "Epoch 112: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.2004e-07 - val_accuracy: 1.0000 - val_loss: 1.2804e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.6835e-07\n",
      "Epoch 113: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.6956e-07 - val_accuracy: 1.0000 - val_loss: 1.2694e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.5738e-07\n",
      "Epoch 114: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.6047e-07 - val_accuracy: 1.0000 - val_loss: 1.2694e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.5073e-07\n",
      "Epoch 115: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.5295e-07 - val_accuracy: 1.0000 - val_loss: 1.2694e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.1251e-07\n",
      "Epoch 116: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.1183e-07 - val_accuracy: 1.0000 - val_loss: 1.2694e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.9186e-07\n",
      "Epoch 117: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.9234e-07 - val_accuracy: 1.0000 - val_loss: 1.2583e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.5685e-07\n",
      "Epoch 118: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.5775e-07 - val_accuracy: 1.0000 - val_loss: 1.2583e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.9324e-07\n",
      "Epoch 119: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.9275e-07 - val_accuracy: 1.0000 - val_loss: 1.2583e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.0181e-07\n",
      "Epoch 120: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.0173e-07 - val_accuracy: 1.0000 - val_loss: 1.2583e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.5856e-07\n",
      "Epoch 121: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.5939e-07 - val_accuracy: 1.0000 - val_loss: 1.2473e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.3106e-07\n",
      "Epoch 122: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.3333e-07 - val_accuracy: 1.0000 - val_loss: 1.2473e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1002e-07\n",
      "Epoch 123: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.0835e-07 - val_accuracy: 1.0000 - val_loss: 1.2473e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.7207e-07\n",
      "Epoch 124: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.7256e-07 - val_accuracy: 1.0000 - val_loss: 1.2473e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.7031e-07\n",
      "Epoch 125: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.7015e-07 - val_accuracy: 1.0000 - val_loss: 1.2252e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.5082e-07\n",
      "Epoch 126: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.5113e-07 - val_accuracy: 1.0000 - val_loss: 1.2252e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.9966e-07\n",
      "Epoch 127: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.9873e-07 - val_accuracy: 1.0000 - val_loss: 1.2252e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.6601e-07\n",
      "Epoch 128: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.6678e-07 - val_accuracy: 1.0000 - val_loss: 1.2142e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.3371e-07\n",
      "Epoch 129: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.3639e-07 - val_accuracy: 1.0000 - val_loss: 1.2142e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.8705e-07\n",
      "Epoch 130: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.8605e-07 - val_accuracy: 1.0000 - val_loss: 1.2142e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.0896e-07\n",
      "Epoch 131: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.0639e-07 - val_accuracy: 1.0000 - val_loss: 1.2031e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.8563e-07\n",
      "Epoch 132: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.8441e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.7892e-07\n",
      "Epoch 133: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.7799e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.0746e-07\n",
      "Epoch 134: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.0490e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.4195e-07\n",
      "Epoch 135: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.4274e-07 - val_accuracy: 1.0000 - val_loss: 1.1811e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.4304e-07\n",
      "Epoch 136: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.4433e-07 - val_accuracy: 1.0000 - val_loss: 1.1811e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.1061e-07\n",
      "Epoch 137: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.1314e-07 - val_accuracy: 1.0000 - val_loss: 1.1811e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.6156e-07\n",
      "Epoch 138: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.6160e-07 - val_accuracy: 1.0000 - val_loss: 1.1811e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.8201e-07\n",
      "Epoch 139: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.8031e-07 - val_accuracy: 1.0000 - val_loss: 1.1811e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.4600e-07\n",
      "Epoch 140: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.4642e-07 - val_accuracy: 1.0000 - val_loss: 1.1700e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.7521e-07\n",
      "Epoch 141: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.7391e-07 - val_accuracy: 1.0000 - val_loss: 1.1700e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 2.2137e-07\n",
      "Epoch 142: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.2250e-07 - val_accuracy: 1.0000 - val_loss: 1.1590e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.2865e-07\n",
      "Epoch 143: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.2929e-07 - val_accuracy: 1.0000 - val_loss: 1.1479e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.6660e-07\n",
      "Epoch 144: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.6568e-07 - val_accuracy: 1.0000 - val_loss: 1.1479e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.6603e-07\n",
      "Epoch 145: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.6495e-07 - val_accuracy: 1.0000 - val_loss: 1.1369e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.0978e-07\n",
      "Epoch 146: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.1153e-07 - val_accuracy: 1.0000 - val_loss: 1.1259e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.1363e-07\n",
      "Epoch 147: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.1630e-07 - val_accuracy: 1.0000 - val_loss: 1.1148e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.3915e-07\n",
      "Epoch 148: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 2.3929e-07 - val_accuracy: 1.0000 - val_loss: 1.0928e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.6327e-07\n",
      "Epoch 149: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.6204e-07 - val_accuracy: 1.0000 - val_loss: 1.0928e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.2729e-07\n",
      "Epoch 150: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.2815e-07 - val_accuracy: 1.0000 - val_loss: 1.0928e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.8060e-07\n",
      "Epoch 151: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 2.7870e-07 - val_accuracy: 1.0000 - val_loss: 1.0928e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.1596e-07\n",
      "Epoch 152: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.1689e-07 - val_accuracy: 1.0000 - val_loss: 1.0817e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.3089e-07\n",
      "Epoch 153: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.3147e-07 - val_accuracy: 1.0000 - val_loss: 1.0817e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.1543e-07\n",
      "Epoch 154: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 2.1665e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.2468e-07\n",
      "Epoch 155: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.2537e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.4045e-07\n",
      "Epoch 156: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.4026e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.2708e-07\n",
      "Epoch 157: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 2.2645e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 2.2887e-07\n",
      "Epoch 158: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.2936e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.4415e-07\n",
      "Epoch 159: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 2.4462e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 2.0090e-07\n",
      "Epoch 160: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.0332e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.4681e-07\n",
      "Epoch 161: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.4613e-07 - val_accuracy: 1.0000 - val_loss: 1.0707e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.1896e-07\n",
      "Epoch 162: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.1926e-07 - val_accuracy: 1.0000 - val_loss: 1.0486e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.6113e-07\n",
      "Epoch 163: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 2.6050e-07 - val_accuracy: 1.0000 - val_loss: 1.0486e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.3789e-07\n",
      "Epoch 164: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.3798e-07 - val_accuracy: 1.0000 - val_loss: 1.0376e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.1012e-07\n",
      "Epoch 165: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 2.1082e-07 - val_accuracy: 1.0000 - val_loss: 1.0265e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 2.0974e-07\n",
      "Epoch 166: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 2.1019e-07 - val_accuracy: 1.0000 - val_loss: 1.0265e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.0952e-07\n",
      "Epoch 167: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.1049e-07 - val_accuracy: 1.0000 - val_loss: 1.0265e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.1835e-07\n",
      "Epoch 168: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 2.1814e-07 - val_accuracy: 1.0000 - val_loss: 1.0265e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.5598e-07\n",
      "Epoch 169: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.5415e-07 - val_accuracy: 1.0000 - val_loss: 1.0265e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.1482e-07\n",
      "Epoch 170: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.1554e-07 - val_accuracy: 1.0000 - val_loss: 1.0155e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.8468e-07\n",
      "Epoch 171: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.8626e-07 - val_accuracy: 1.0000 - val_loss: 1.0155e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.2123e-07\n",
      "Epoch 172: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.2078e-07 - val_accuracy: 1.0000 - val_loss: 1.0044e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.9334e-07\n",
      "Epoch 173: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 1.9439e-07 - val_accuracy: 1.0000 - val_loss: 1.0044e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 2.0277e-07\n",
      "Epoch 174: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 2.0306e-07 - val_accuracy: 1.0000 - val_loss: 1.0044e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.0529e-07\n",
      "Epoch 175: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.0517e-07 - val_accuracy: 1.0000 - val_loss: 1.0044e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.3841e-07\n",
      "Epoch 176: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.3671e-07 - val_accuracy: 1.0000 - val_loss: 1.0044e-07 - learning_rate: 1.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.9481e-07\n",
      "Epoch 177: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.9548e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.1376e-07\n",
      "Epoch 178: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.1269e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.4060e-07\n",
      "Epoch 179: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.4393e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.9016e-07\n",
      "Epoch 180: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.9227e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.2203e-07\n",
      "Epoch 181: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.2066e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.9406e-07\n",
      "Epoch 182: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.9398e-07 - val_accuracy: 1.0000 - val_loss: 9.8237e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.8839e-07\n",
      "Epoch 183: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.8910e-07 - val_accuracy: 1.0000 - val_loss: 9.8237e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.2112e-07\n",
      "Epoch 184: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.2037e-07 - val_accuracy: 1.0000 - val_loss: 9.8237e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.8605e-07\n",
      "Epoch 185: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.8604e-07 - val_accuracy: 1.0000 - val_loss: 9.6030e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.9204e-07\n",
      "Epoch 186: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.9225e-07 - val_accuracy: 1.0000 - val_loss: 9.6030e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.7582e-07\n",
      "Epoch 187: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.7749e-07 - val_accuracy: 1.0000 - val_loss: 9.6030e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.0570e-07\n",
      "Epoch 188: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.0498e-07 - val_accuracy: 1.0000 - val_loss: 9.4926e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.9450e-07\n",
      "Epoch 189: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.9464e-07 - val_accuracy: 1.0000 - val_loss: 9.4926e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.2745e-07\n",
      "Epoch 190: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.2617e-07 - val_accuracy: 1.0000 - val_loss: 9.4926e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.5901e-07\n",
      "Epoch 191: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.6070e-07 - val_accuracy: 1.0000 - val_loss: 9.4926e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.9406e-07\n",
      "Epoch 192: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.9422e-07 - val_accuracy: 1.0000 - val_loss: 9.4926e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.1315e-07\n",
      "Epoch 193: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.1188e-07 - val_accuracy: 1.0000 - val_loss: 9.4926e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.6736e-07\n",
      "Epoch 194: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 1.6898e-07 - val_accuracy: 1.0000 - val_loss: 9.3822e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.7034e-07\n",
      "Epoch 195: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.7071e-07 - val_accuracy: 1.0000 - val_loss: 9.2718e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.0912e-07\n",
      "Epoch 196: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 2.0780e-07 - val_accuracy: 1.0000 - val_loss: 9.1614e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.6803e-07\n",
      "Epoch 197: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.6908e-07 - val_accuracy: 1.0000 - val_loss: 9.0511e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.6882e-07\n",
      "Epoch 198: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.6980e-07 - val_accuracy: 1.0000 - val_loss: 9.0511e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.9187e-07\n",
      "Epoch 199: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.9181e-07 - val_accuracy: 1.0000 - val_loss: 8.9407e-08 - learning_rate: 1.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.8882e-07\n",
      "Epoch 200: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.8844e-07 - val_accuracy: 1.0000 - val_loss: 8.9407e-08 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 199.\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 결과 시각화\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
